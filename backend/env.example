# Local RAG Application Configuration
# Copy this file to .env in project root and update with your values

# ChromaDB Settings
CHROMA_HOST=localhost
CHROMA_PORT=8002
CHROMA_COLLECTION=rag_documents
CHROMA_PERSIST_DIR=./chroma_db

# Embedding Model Settings
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_MODEL_PATH=./models/embedding/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu

# vLLM Settings (for local LLM inference)
VLLM_HOST=localhost
VLLM_PORT=8001
VLLM_BASE_URL=http://localhost:8001
VLLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2
VLLM_MODEL_PATH=./models/llm/Mistral-7B-Instruct-v0.2
VLLM_ENABLED=true
VLLM_TIMEOUT=60
VLLM_MAX_RETRIES=3

# Alternative LLM Settings (if not using vLLM)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1
# USE_OPENAI=false

# Local Transformers Settings (Windows-friendly, no vLLM required)
USE_LOCAL_TRANSFORMERS=true
LOCAL_MODEL_ID=mistralai/Mistral-7B-Instruct-v0.2
LOCAL_DEVICE=cpu

# Chunking Settings
CHUNK_SIZE=300
CHUNK_OVERLAP=50

# RAG Settings
TOP_K=5
SIMILARITY_THRESHOLD=0.5

# Document Storage
UPLOAD_DIR=./uploads
MAX_FILE_SIZE_MB=50
ALLOWED_FILE_TYPES=pdf,txt,docx

# Local Models Directory
MODELS_DIR=./models

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# Logging
LOG_LEVEL=INFO

